{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Telecom Churn Prediction Project \n",
    "\n",
    "## Modeling and Grid Search for a Hybrid\n",
    "\n",
    "In this notebook we're going to explore using a hybrid model.<br>\n",
    "\n",
    "The telecom customers in this dataset can be split into two distinct groups based on the length of their contract.  Customers with month to month contracts represent 88% of the churn.  It seems possible that two different models could be developed, one for each of the groups.  On the final model testing the predictions would then come from the appropriate model.\n",
    "<br>\n",
    "<br>\n",
    "The original training dataset was split into two groups.  Each of these groups was then used as the input to a grid search of the same classifiers used for the single classifier solutions.  The best model for each group will be used in the final training/testing phase of the process and compared to the single classifier models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "sys.path.append('/Users/maboals/Documents/Work/Programming/PyStuff/MyTools/src')\n",
    "from MLModelingTools import model_test, model_testN\n",
    "\n",
    "sys.path.append('../src')\n",
    "from my_eval_tools import calc_roc_data\n",
    "from my_eval_tools import calc_hybrid_roc_data \n",
    "from my_eval_tools import hybrid_predict, hybrid_predict_proba\n",
    "from my_eval_tools import calc_pr_sweep\n",
    "from my_eval_tools import predict_sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maboals/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from yellowbrick.classifier import ClassificationReport\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the clean training data\n",
    "\n",
    "Read the training data file.  This file was created by running the notebooks:\n",
    "* Telecom to SQL\n",
    "* Telecom clean and eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customerID', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure',\n",
       "       'PhoneService', 'MultipleLines', 'OnlineSecurity', 'OnlineBackup',\n",
       "       'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n",
       "       'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges',\n",
       "       'Churn', 'Month-to-month', 'One year', 'DSL', 'Fiber optic', 'Female'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the csv file save by the clean/eda notebook\n",
    "train_df = pd.read_csv('../data/churn_train_clean.csv')\n",
    "\n",
    "\n",
    "# Sometimes the index column is read as an unnamed column, if so drop it\n",
    "if 'Unnamed: 0' in train_df.columns :\n",
    "    train_df = train_df.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split off just the portion of the dataset that is month to month customers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2389 entries, 6 to 5281\n",
      "Data columns (total 16 columns):\n",
      "SeniorCitizen       2389 non-null int64\n",
      "Partner             2389 non-null int64\n",
      "Dependents          2389 non-null int64\n",
      "tenure              2389 non-null int64\n",
      "PhoneService        2389 non-null int64\n",
      "MultipleLines       2389 non-null int64\n",
      "OnlineSecurity      2389 non-null int64\n",
      "OnlineBackup        2389 non-null int64\n",
      "DeviceProtection    2389 non-null int64\n",
      "TechSupport         2389 non-null int64\n",
      "StreamingTV         2389 non-null int64\n",
      "StreamingMovies     2389 non-null int64\n",
      "MonthlyCharges      2389 non-null float64\n",
      "TotalCharges        2389 non-null float64\n",
      "Fiber optic         2389 non-null int64\n",
      "Female              2389 non-null int64\n",
      "dtypes: float64(2), int64(14)\n",
      "memory usage: 317.3 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, (2389,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define which columns we're going to use in our modeling.\n",
    "train_columns1 = ['Month-to-month', 'SeniorCitizen', 'Partner', 'Dependents', \\\n",
    "       'tenure', 'PhoneService', 'MultipleLines',  \\\n",
    "       'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', \\\n",
    "       'StreamingTV', 'StreamingMovies', 'MonthlyCharges', 'TotalCharges', \\\n",
    "       'Fiber optic', 'Female']\n",
    "\n",
    "train_columns2 = train_columns1.copy()\n",
    "train_columns2.append('Churn')\n",
    "\n",
    "train_columns = train_columns1\n",
    "\n",
    "month_df = train_df[train_df['Month-to-month'] == 1]\n",
    "not_month_df = train_df[train_df['Month-to-month'] == 0]\n",
    "\n",
    "X_month = month_df[train_columns].drop('Month-to-month', axis=1)\n",
    "y_month= month_df['Churn']\n",
    "\n",
    "X_not_month = not_month_df[train_columns].drop('Month-to-month', axis=1)\n",
    "y_not_month = not_month_df['Churn']\n",
    "X_not_month.info(), y_not_month.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the original dataset into train and validation groups\n",
    "#  set stratify to true so both classes are represented it the splits\n",
    "X_nm_train, X_nm_test, y_nm_train, y_nm_test = train_test_split(X_not_month, y_not_month, test_size=0.2)\n",
    "\n",
    "\n",
    "X_m_train, X_m_test, y_m_train, y_m_test = train_test_split(X_month, y_month, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, test split\n",
    "\n",
    "Make a training data subset and a validation data subset\n",
    "\n",
    "Then make a balanced training dataset using smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a balance set for model training\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train_month_smt, y_train_month_smt = sm.fit_resample(X_m_train, y_m_train)\n",
    "X_train_not_month_smt, y_train_not_month_smt = sm.fit_resample(X_nm_train, y_nm_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline with Logistic Regression\n",
    "\n",
    "Make a process pipeline to use the grid search cross validation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "log_model = LogisticRegression()\n",
    "steps = [('smt', sm), ('LOG', log_model)]\n",
    "\n",
    "pipeline = Pipeline(steps) # define the pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_param_grid = {\n",
    "    'smt__random_state': [45],\n",
    "    'LOG__solver': ['liblinear'],\n",
    "    'LOG__C' : [0.001, 0.01, 0.02, 0.03, 0.07, 0.1, 0.5, 0.75, 1, 1.5, 3, 10, 20],\n",
    "    'LOG__penalty' : ['l1', 'l2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_grid_month = GridSearchCV(pipeline, param_grid=log_param_grid, scoring='recall',cv=5, n_jobs=-1)\n",
    "log_grid_not_month = GridSearchCV(pipeline, param_grid=log_param_grid, scoring='recall', cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.70\n",
      "{'LOG__C': 10, 'LOG__penalty': 'l1', 'LOG__solver': 'liblinear', 'smt__random_state': 45}\n",
      "score = 0.34\n",
      "{'LOG__C': 10, 'LOG__penalty': 'l1', 'LOG__solver': 'liblinear', 'smt__random_state': 45}\n"
     ]
    }
   ],
   "source": [
    "log_grid_month.fit(X_train_month_smt, y_train_month_smt)\n",
    "log_grid_not_month.fit(X_train_not_month_smt, y_train_not_month_smt)\n",
    "\n",
    "print(\"score = %3.2f\" %(log_grid_month.score(X_m_test,y_m_test)))\n",
    "print(log_grid_month.best_params_)\n",
    "\n",
    "print(\"score = %3.2f\" %(log_grid_not_month.score(X_nm_test,y_nm_test)))\n",
    "print(log_grid_not_month.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nrecall\\nscore = 0.76\\n{'LOG__C': 0.01, 'LOG__penalty': 'l1', 'LOG__solver': 'liblinear', 'smt__random_state': 45}\\n\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "recall\n",
    "score = 0.76\n",
    "{'LOG__C': 0.01, 'LOG__penalty': 'l1', 'LOG__solver': 'liblinear', 'smt__random_state': 45}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model validation pipeline and do grid search for KNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "sm = SMOTE(random_state=42)\n",
    "knn = KNeighborsClassifier()\n",
    "steps = [('smt', sm), ('KNN', knn)]\n",
    "\n",
    "pipeline = Pipeline(steps) # define the pipeline object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the parameters for the pipeline steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_param_grid = {\n",
    "    'smt__random_state': [45],\n",
    "    'KNN__n_neighbors': [2, 4, 6, 8, 10, 20, 50],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use grid search to find the optimum parameters for the Knn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid_month = GridSearchCV(pipeline, param_grid=knn_param_grid, scoring='recall', cv=5, n_jobs=-1)\n",
    "knn_grid_not_month = GridSearchCV(pipeline, param_grid=knn_param_grid, scoring='recall', cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.60\n",
      "{'KNN__n_neighbors': 20, 'smt__random_state': 45}\n",
      "score = 0.22\n",
      "{'KNN__n_neighbors': 8, 'smt__random_state': 45}\n"
     ]
    }
   ],
   "source": [
    "knn_grid_month.fit(X_train_month_smt, y_train_month_smt)\n",
    "print(\"score = %3.2f\" %(knn_grid_month.score(X_m_test,y_m_test)))\n",
    "print(knn_grid_month.best_params_)\n",
    "\n",
    "knn_grid_not_month.fit(X_train_not_month_smt, y_train_not_month_smt)\n",
    "print(\"score = %3.2f\" %(knn_grid_month.score(X_nm_test,y_nm_test)))\n",
    "print(knn_grid_not_month.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrecall\\nscore = 0.75\\n{'KNN__n_neighbors': 10, 'smt__random_state': 45}\\n\\n\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "recall\n",
    "score = 0.75\n",
    "{'KNN__n_neighbors': 10, 'smt__random_state': 45}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "Build the pipeline and search parameter grid for random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "rf = RandomForestClassifier()\n",
    "steps = [('smt', sm), ('RFC', rf)]\n",
    "\n",
    "rf_pipeline = Pipeline(steps) # define the pipeline object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_param_grid = {\n",
    "    'smt__random_state': [10],\n",
    "    'RFC__n_estimators': [50, 100, 150, 200, 1000],\n",
    "    'RFC__max_depth' : [2,3,4],\n",
    "    'RFC__max_features' : [5, 10, 15],\n",
    "    'RFC__criterion' : ['gini', 'entropy'],\n",
    "    'RFC__random_state' :[42]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid_month = GridSearchCV(rf_pipeline, param_grid=rf_param_grid, scoring='recall', cv=5, n_jobs=-1)\n",
    "rf_grid_not_month = GridSearchCV(rf_pipeline, param_grid=rf_param_grid, scoring='recall', cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.71\n",
      "{'RFC__criterion': 'entropy', 'RFC__max_depth': 2, 'RFC__max_features': 5, 'RFC__n_estimators': 1000, 'RFC__random_state': 42, 'smt__random_state': 10}\n"
     ]
    }
   ],
   "source": [
    "rf_grid_month.fit(X_train_month_smt, y_train_month_smt)\n",
    "\n",
    "print(\"score = %3.2f\" %(rf_grid_month.score(X_m_test,y_m_test)))\n",
    "print(rf_grid_month.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score = 0.69\n",
      "{'RFC__criterion': 'entropy', 'RFC__max_depth': 4, 'RFC__max_features': 15, 'RFC__n_estimators': 1000, 'RFC__random_state': 42, 'smt__random_state': 10}\n"
     ]
    }
   ],
   "source": [
    "rf_grid_not_month.fit(X_train_not_month_smt, y_train_not_month_smt)\n",
    "\n",
    "print(\"score = %3.2f\" %(rf_grid_not_month.score(X_nm_test,y_nm_test)))\n",
    "print(rf_grid_not_month.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
